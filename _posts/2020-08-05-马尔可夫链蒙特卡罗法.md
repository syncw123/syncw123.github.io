---
layout:     post
title:      马尔可夫链蒙特卡罗法
subtitle:   "Metropolis-Hastings算法 与 吉布斯抽样"
date:       2020-08-05
author:     Syncw
header-img: img/post_img/machine-learning/machine.jpg
catalog: true
tags:
    - 机器学习
---

## 马尔可夫链蒙特卡罗法

马尔可夫链蒙特卡罗法是以马尔可夫链为概率模型的蒙特卡罗积分方法。<br>
假设我们的目标是对一个概率分布 p(x) 进行随机抽样，或者是求函数 f(x) 关于概率分布 p(x) 的数学
期望。<br>
可以采用传统的蒙特卡罗法，如接受-拒绝法、重要性抽样法，也可以使用马尔可夫链蒙特卡罗法。<br>
马尔可夫链蒙特卡罗法更适合于随机变量是多元的、密度函数是非标准形式的、随机变量各分量不独立等情况。
<br>

#### 基本思想
![马尔可夫链蒙特卡罗法的基本思想](https://www.syncw.work/img/post_img/machine-learning/Markov-chain-Monte-Carlo/基本思想.png)

<b>如何构建具体的马尔可夫链是该方法的关键。</b> 
<br>
连续变量的时候，需要定义转移核函数；离散变量的时候，需要定义转移矩阵。一个方法是定义特殊的转移核函数或者转移矩阵，构建可逆马尔可夫链，这样可以保证遍历定理成立。<br>
由于这个马尔可夫链满足遍历定理，随机游走的起始点并不影响得到的结果，即从不同的起始点出发，都会收敛到同一平稳分布 。
<br>
马尔可夫链蒙特卡罗法的收敛性的判断通常是经验性的。

>比如，在马尔可夫链上进行随机游走，检验遍历均值是否收敛。具体地，每隔一段时间取一次样本，得到多个样本以后，计算遍历均值，当计算的均值稳定后，认为马尔可夫链已经收敛。<br>再比如，在马尔可夫链上井行进行多个随机游走，比较各个随机游走的遍历均值是否接近一致。

马尔可夫链蒙特卡罗法中得到的样本序列，相邻的样本点是相关的 ，而不是独立的。
因此，在需要独立样本时，可以在该样本序列中再次进行随机抽样，比如每隔一段时间取一次样本，将这样得到的子样本集合作为一个独立样本集合。
<br>
一般来说马尔可夫链蒙特卡罗法比接受-拒绝法效率更高，没有大量被拒绝的样本，虽然燃烧期的样本也要抛弃。


#### 基本步骤

![马尔可夫链蒙特卡罗法的基本步骤](https://www.syncw.work/img/post_img/machine-learning/Markov-chain-Monte-Carlo/基本步骤.png)

<!-- ============================= Metropolis-Hastings 算法 =====================  -->

## Metropolis-Hastings算法

马尔科夫链蒙特卡罗法的一个代表性算法。

<br><br>

#### 马尔可夫链

![Metropolis-Hastings算法使用的马尔可夫链](https://www.syncw.work/img/post_img/machine-learning/Markov-chain-Monte-Carlo/MH算法的马尔可夫链.png)

<b>建议分布</b>
![建议分布](https://www.syncw.work/img/post_img/machine-learning/Markov-chain-Monte-Carlo/建议分布.png)


#### Metropolis-Hastings算法基本思想
![MH算法基本思想](https://www.syncw.work/img/post_img/machine-learning/Markov-chain-Monte-Carlo/MH的基本思想.png)

#### Metropolis-Hastings算法步骤
![MH算法步骤](https://www.syncw.work/img/post_img/machine-learning/Markov-chain-Monte-Carlo/MH算法步骤.png)


<!-- ============================= 满条件分布 =====================  -->

## 满条件分布

![满条件分布](https://www.syncw.work/img/post_img/machine-learning/Markov-chain-Monte-Carlo/满条件分布.png)


<!-- ============================= 单分量 Metropolis-Hastings 算法 =====================  -->

## 单分量 Metropolis-Hastings算法

在 Metropolis-Hastings 算法中 ， 有时随机变量可能不是标量，而是多元变量。对于多元随机变量 的概率分布进行抽样，可以使用 单分量 Metropolis-Hastings算法实现。

![单分量MH算法](https://www.syncw.work/img/post_img/machine-learning/Markov-chain-Monte-Carlo/单分量MH算法.png)

单分量 Metropolis-Hastings算法 的基本思想 与 Metropolis-Hastings算法 相同。唯一的区别在于使用  <b>K步迭代</b> 来实现随机变量的一次抽样。即，
>依次对多元随机变量中的每一个分量的条件概率分布（满条件分布） 分别进行抽样 ， 从而实现对整个多元随机变量的一次抽样。

#### K步迭代

![K步迭代](https://www.syncw.work/img/post_img/machine-learning/Markov-chain-Monte-Carlo/K步迭代.png)

#### 单分量Metropolis-Hastings算法步骤

![单分量MH算法步骤](https://www.syncw.work/img/post_img/machine-learning/Markov-chain-Monte-Carlo/单分量MH算法步骤.png)

#### 单分量Metropolis-Hastings算法图示

![单分量MH算法图解示例](https://www.syncw.work/img/post_img/machine-learning/Markov-chain-Monte-Carlo/单分量MH算法图解示例.png)


<!-- =============================  吉布斯抽样 =====================  -->

## 吉布斯抽样

吉布斯抽样 CGibbs sampling) 用于多元联合分布的抽样和估计。吉布斯抽样是单分量 Metropolis-Hastings 算法的特殊情况。


#### 马尔可夫链

![吉布斯抽样的马尔可夫链](https://www.syncw.work/img/post_img/machine-learning/Markov-chain-Monte-Carlo/吉布斯抽样的马尔可夫链.png)

#### 吉布斯抽样算法思想

![吉布斯抽样算法思想](https://www.syncw.work/img/post_img/machine-learning/Markov-chain-Monte-Carlo/吉布斯抽样思想.png)

#### 吉布斯抽样的一次迭代

![吉布斯抽样一次迭代](https://www.syncw.work/img/post_img/machine-learning/Markov-chain-Monte-Carlo/吉布斯抽样一次迭代.png)

#### 吉布斯抽样算法步骤

![吉布斯抽样算法步骤](https://www.syncw.work/img/post_img/machine-learning/Markov-chain-Monte-Carlo/吉布斯抽样算法步骤.png)

#### 吉布斯抽样图示

![吉布斯抽样图示](https://www.syncw.work/img/post_img/machine-learning/Markov-chain-Monte-Carlo/吉布斯抽样图示.png)

## 吉布斯抽样 与 单分量Metropolis-Hastings算法

![吉布斯抽样与单分量MH算法](https://www.syncw.work/img/post_img/machine-learning/Markov-chain-Monte-Carlo/吉布斯抽样与单分量MH算法.png)











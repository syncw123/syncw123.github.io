---
layout:     post
title:      对抗性机器学习中博弈论方法综述
subtitle:   ""
date:       2020-06-21
author:     Syncw
header-img: img/post_img/machine-learning/machine.jpg
catalog: true
tags:
    - 机器学习
    - 博弈论
---

## paper 

<b>A survey of game theoretic approach for adversarial machine learning</b>

<object data="https://www.syncw.work/img/post_img/machine-learning/paper01/paper.pdf" type="application/pdf" width="750px" height="750px">
    <embed src="https://www.syncw.work/img/post_img/machine-learning/paper01/paper.pdf" type="application/pdf">
        <p>If your browser does not support PDFs. Please download the PDF to view it: <a href="https://www.syncw.work/img/post_img/machine-learning/paper01/paper.pdf">Download PDF.</a></p>
    </embed>
</object>

## thinking



## 相关概念
<b>此处仅对相关的概念作一个简单的阐述。后续还需不断学习，以加深对这些概念的理解。</b>
<br>
1. 过度拟合（Overfitting）
	> Overfitting occurs when an algorithm fits the training data perfectly but fails to generalize to the unseen data.
	<br>
	简单来说，过度拟合就是指 模型与训练数据 的拟合度极高，训练误差很小，甚至没有训练误差。但将该模型推广到 一些训练集以外的数据时，误差却较大。或者说  在实际的 数据分布（包含训练集以外的实例）上表现不好。
	<br>
	一个健壮的学习算法，应避免出现 过度拟合的现象。
	<br>
2. 支持向量机（support vector machine [SVM]）
	> 支持向量机（Support Vector Machine, SVM）是一类按监督学习（supervised learning）方式对数据进行 二元分类 的 广义线性分类器（generalized linear classifier）， 其 决策边界 是对学习样本求解的 最大边距超平面（maximum-margin hyperplane） 
	> 
	> SVM使用 铰链损失函数（hinge loss）计算 经验风险（empirical risk）并在 求解系统中加入了  正则化项   以优化  结构风险（structural risk），是一个具有稀疏性和稳健性的分类器 。SVM可以通过  核方法（kernel method）进行 非线性分类，是常见的 核学习（kernel learning）方法之一。   ———— 百度百科
	<br>
	不知所云。。。
	<br>
	关于SVM的详细内容可参考这篇文章：[支持向量机 SVM](https://zhuanlan.zhihu.com/p/77750026?utm_source=wechat_session)




## 后记

由于国内对 github 访问速度较慢，可能会导致 评论组件加载失败。<br>
可尝试刷新页面。若仍不能解决，可联系博主讨论解决方案。


